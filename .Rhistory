#' @keywords t-test
#'
#' @return Numeric indicating temperature \code{temp_F} converted to Celsius.
#'
#' @examples
#' f_to_c(32)
#' f_to_c(212)
#'
#' @export
#t-test function
my_t_test <- function(x, alternative, mu) {
#check for the parameter alternative to be one of the three allowed, if it isn't
if(!(alternative %in% c("two.sided", "less", "greater"))){
warning("alternative not recognized")
}
#saves the length of the vector as n
n <- length(x)
#calculates the t-statistic
test_stat <- (mean(x) - mu) / (sd(x) / sqrt(n))
#calculates the degrees of freedom
df <- n - 1
#calculate p_val lower tail.
p_val <- pt(test_stat, df)
#change p_val to upper tail.
p_val <- if(grepl(alternative, "greater")){
(1 - p_val)
#change p_val to both tails.
} else if(grepl(alternative, "two.sided")){
min(p_val, 1 - p_val) * 2
} else { p_val }
#combines the results in one list
result <- list("test_stat" = test_stat,
"df" = df,
"alternative" = alternative,
"p_val" = p_val
)
#returns the results
return(result)
}
devtools::document()
?my_t_test
---
title: "Lab 3"
author: "Matteo Vindrola"
date: "2/10/2020"
output: html_document
---
<!--- Begin styling code. --->
<style type="text/css">
/* Whole document: */
body{
font-family: "Palatino Linotype", "Book Antiqua", Palatino, serif;
font-size: 12pt;
}
h1.title {
font-size: 38px;
text-align: center;
}
h4.author {
font-size: 18px;
text-align: center;
}
h4.date {
font-size: 18px;
text-align: center;
}
</style>
<!--- End styling code. --->
## Part 1. t-test (10 points)
```{r}
#t-test function
my_t.test <- function(x, alternative, mu) {
#check for the parameter alternative to be one of the three allowed, if it isn't
if(!(alternative %in% c("two.sided", "less", "greater"))){
warning("alternative not recognized")
}
#saves the length of the vector as n
n <- length(x)
#calculates the t-statistic
test_stat <- (mean(x) - mu) / (sd(x) / sqrt(n))
#calculates the degrees of freedom
df <- n - 1
#calculate p_val lower tail.
p_val <- pt(test_stat, df)
#change p_val to upper tail.
p_val <- if(grepl(alternative, "greater")){
(1 - p_val)
#change p_val to both tails.
} else if(grepl(alternative, "two.sided")){
min(p_val, 1 - p_val) * 2
} else { p_val }
#combines the results in one list
result <- list("test_stat" = test_stat,
"df" = df,
"alternative" = alternative,
"p_val" = p_val
)
#returns the results
return(result)
}
```
We set up a vector containing 10 observations from a random normal distribution with mean of 7 and sd of 3. We first use  t.test() with $\mu$ = 3 and the "less" alternative. Then we use  my_t.test() and see the results are the same as for t.test().
```{r}
x <- rnorm(10, mean = 7, 3)
t.test(x, alternative = "less", mu = 3)
my_t.test(x, "less", 3)
```
## Part 2. Linear model (10 points)
```{r}
#Creates my_lm a function that takes in as parameters a formula and a dataset
#returning a table containing the appropiate coefficients for the linear model.
my_lm <- function(formula_lm, data_lm) {
#Extracts model matrix X.
X_lm <- model.matrix(formula_lm, data =  data_lm)
#Extract a model respopnse Y.
Y_lm <- model.response(model.frame(data_lm))
#Estimates linear regression coefficients.
beta_lm <- solve(t(X_lm) %*% X_lm) %*%  t(X_lm) %*% Y_lm
#Estimates the degrees of freedom.
df_lm <- nrow(data_lm) - nrow(beta_lm)
#Estimates the variance.
var_lm <- sum(((Y_lm - X_lm %*% beta_lm )^2)) / df_lm
#Estimates the standard error.
suppressWarnings(std_error_lm <- diag(sqrt(var_lm * solve(t(X_lm) %*% X_lm))))
#Estimates the t value.
t_value_lm <- beta_lm / std_error_lm
#Estimates the p value of the t test.
p_of_t <- pt(abs(t_value_lm), df_lm, lower.tail = FALSE)*2
#Combines coefficients, standard errors, t values and p values of the t test,
#all in one matrix
final_matrix <- cbind(beta_lm, std_error_lm, t_value_lm, p_of_t)
#appropiatly names the culums of the matrix
colnames(final_matrix) <-  c("Estimate", "Std. Error", "t value", "Pr(>|t|)")
#returns the final matrix as a table
return(as.table(final_matrix))
}
```
devtools::document()
?my_t_test
devtools::document()
?my_t_test
?my_t_test
devtools::document()
?my_t_test
devtools::document()
bash <(curl -s https://codecov.io/bash)
bash <(curl -s https://codecov.io/bash) -t token
bash <(curl -s https://codecov.io/gh/MatteVin/myfirstpackage) -t token
?lm
?my_t_test()
devtools::document()
devtools::test()
devtools::test()
pt?
?pt
model.frame
?model.frame
?model.frame
devtools::document()
devtools::test()
?lm
?my_lm
?lm
?sample
?data.frame
?data_train
?select
library(tidyverse)
?select
?filter
?knn
?mean
?sd
?sample
data(gapminder)
gapminder
import(gapminder)
library(gapminder)
data(gapminder)
force(gapminder)
my_gapminder <- gapminder
usethis::use_data(my_gapminder)
?gapminder
?my_iris
?my_t_test
View(gapminder)
my_gapminder[,6][,5]
my_gapminder[,6]
my_gapminder[,5]
irirs
iris
devtools::document()
usethis::use_data(my_gapminder)
devtool::check()
devtools::check()
devtools::bash
devtools::build()
library(myfirstpackage)
myfirstpackage::my_gapminder
View(my_gapminder)
View(my_gapminder)
View(my_gapminder)
View(my_gapminder)
devtools::document()
devtools::check()
?knn_cv
??knn_cv
my_iris
my_knn_cv(my_iris[2:4], my_iris[2:4], 3, 5)
my_knn_cv(my_iris[, 2:4], my_iris[, 1], 3, 5)
my_knn_cv( train = my_iris[, 2:4], cl = my_iris[, 1], k_nn = 3,K_cv= 5)
my_knn_cv( train = my_iris[, 2:4], cl = my_iris[, 1], k_nn = 3,k_cv= 5)
my_iris[, 1]
my_iris[, 2:4]
my_knn_cv(my_iris[, 2:4], my_iris[, 1], 3, 5)
my_iris[, 2]
ex_train <- data.frame(my_iris[, 2], my_iris[, 3], my_iris[, 4])
true_val <- my_iris[1]
my_knn_cv(ex_train, true_val, 3, 5)
knitr::opts_chunk$set(echo = TRUE)
#My k-Nearest Neighbors Cross-Validation function
my_knn_cv <- function(train, cl, k_nn, k_cv){
# Split data in k_cv parts, randomly
folds <- sample(rep(1:k_cv, length = nrow(train)))
# Combines input data
data <- data.frame(train, cl, folds)
#initializes cv error as 0
cv_err <- 0
#loops trough the different folds testing one against the rest
for(i in 1:k_cv){
#store training data for the iteration
data_train <- data %>% filter(folds != i)
#records the response for the training data
cl_train <- data_train[["cl"]]
#eliminates the folds and responses from the data
data_train <- data_train %>% select(-cl, -folds)
#store testing data for the iteration
data_test <- data %>% filter(folds == i)
#records the response for the testing data
cl_test <- data_test[["cl"]]
#eliminates the folds and responses from the data
data_test <- data_test %>% select(-cl, -folds)
#pedics the response of the test data suing k-Nearest Neighbors (k = k_nn)
predict_cv <- knn(train = data_train,
cl = cl_train,
test = data_test,
k = k_nn
)
#calculates and compunds the average cv errro
cv_err <- ((sum(ifelse(cl_test == predict_cv, 0, 1)) / length(cl_test)) +
cv_err * (i - 1)) / i
}
#stores the predictions of all the data using all the data for training.
class <- knn(train = train, cl = cl, test = train, k = k_nn)
#return results
result <- list("class" = class, "cv_err" = cv_err)
return(result)
}
devtools::document()
devtools::check()
devtools::check()
#My k-Nearest Neighbors Cross-Validation function
my_knn_cv <- function(train, cl, k_nn, k_cv){
# Split data in k_cv parts, randomly
folds <- sample(rep(1:k_cv, length = nrow(train)))
# Combines input data
data <- data.frame(train, cl, folds)
#initializes cv error as 0
cv_err <- 0
#loops trough the different folds testing one against the rest
for(i in 1:k_cv){
#store training data for the iteration
data_train <- data %>% filter(folds != i)
#records the response for the training data
cl_train <- data_train[["cl"]]
#eliminates the folds and responses from the data
data_train <- data_train %>% select(-cl, -folds)
#store testing data for the iteration
data_test <- data %>% filter(folds == i)
#records the response for the testing data
cl_test <- data_test[["cl"]]
#eliminates the folds and responses from the data
data_test <- data_test %>% select(-cl, -folds)
#pedics the response of the test data suing k-Nearest Neighbors (k = k_nn)
predict_cv <- knn(train = data_train,
cl = cl_train,
test = data_test,
k = k_nn
)
#calculates and compunds the average cv errro
cv_err <- ((sum(ifelse(cl_test == predict_cv, 0, 1)) / length(cl_test)) +
cv_err * (i - 1)) / i
}
#stores the predictions of all the data using all the data for training.
class <- knn(train = train, cl = cl, test = train, k = k_nn)
#return results
result <- list("class" = class, "cv_err" = cv_err)
return(result)
}
#run my_knn_cv with k_nn = 1
predict_knn_1 <- my_knn_cv(train = iris[,-5], cl = iris[,5], k_nn = 1, k_cv = 5)
#loops trough the different folds testing one against the rest
for(i in 1:k_cv){
#store training data for the iteration
data_train <- data %>% filter(folds != i)
#records the response for the training data
cl_train <- data_train[["cl"]]
#eliminates the folds and responses from the data
data_train <- data_train %>% select(-cl, -folds)
#store testing data for the iteration
data_test <- data %>% filter(folds == i)
#records the response for the testing data
cl_test <- data_test["cl"]
#eliminates the folds and responses from the data
data_test <- data_test %>% select(-cl, -folds)
#pedics the response of the test data suing k-Nearest Neighbors (k = k_nn)
predict_cv <- knn(train = data_train,
cl = cl_train,
test = data_test,
k = k_nn
)
#calculates and compunds the average cv errro
cv_err <- ((sum(ifelse(cl_test == predict_cv, 0, 1)) / length(cl_test)) +
cv_err * (i - 1)) / i
}
#My k-Nearest Neighbors Cross-Validation function
my_knn_cv <- function(train, cl, k_nn, k_cv){
# Split data in k_cv parts, randomly
folds <- sample(rep(1:k_cv, length = nrow(train)))
# Combines input data
data <- data.frame(train, cl, folds)
#initializes cv error as 0
cv_err <- 0
#loops trough the different folds testing one against the rest
for(i in 1:k_cv){
#store training data for the iteration
data_train <- data %>% filter(folds != i)
#records the response for the training data
cl_train <- data_train[["cl"]]
#eliminates the folds and responses from the data
data_train <- data_train %>% select(-cl, -folds)
#store testing data for the iteration
data_test <- data %>% filter(folds == i)
#records the response for the testing data
cl_test <- data_test["cl"]
#eliminates the folds and responses from the data
data_test <- data_test %>% select(-cl, -folds)
#pedics the response of the test data suing k-Nearest Neighbors (k = k_nn)
predict_cv <- knn(train = data_train,
cl = cl_train,
test = data_test,
k = k_nn
)
#calculates and compunds the average cv errro
cv_err <- ((sum(ifelse(cl_test == predict_cv, 0, 1)) / length(cl_test)) +
cv_err * (i - 1)) / i
}
#stores the predictions of all the data using all the data for training.
class <- knn(train = train, cl = cl, test = train, k = k_nn)
#return results
result <- list("class" = class, "cv_err" = cv_err)
return(result)
}
#run my_knn_cv with k_nn = 1
predict_knn_1 <- my_knn_cv(train = iris[,-5], cl = iris[,5], k_nn = 1, k_cv = 5)
?data.frame
#My k-Nearest Neighbors Cross-Validation function
#my_knn_cv <- function(train, cl, k_nn, k_cv){
# Split data in k_cv parts, randomly
folds <- sample(rep(1:k_cv, length = nrow(train)))
#My k-Nearest Neighbors Cross-Validation function
train = iris[,-5]
cl = iris[,5]
k_nn = 1
k_cv = 5
#my_knn_cv <- function(train, cl, k_nn, k_cv){
# Split data in k_cv parts, randomly
folds <- sample(rep(1:k_cv, length = nrow(train)))
# Combines input data
data <- data.frame(train, cl, folds)
#initializes cv error as 0
cv_err <- 0
#loops trough the different folds testing one against the rest
for(i in 1:k_cv){
#store training data for the iteration
data_train <- data %>% filter(folds != i)
#records the response for the training data
cl_train <- data_train[["cl"]]
#eliminates the folds and responses from the data
data_train <- data_train %>% select(-cl, -folds)
#store testing data for the iteration
data_test <- data %>% filter(folds == i)
#records the response for the testing data
cl_test <- data_test["cl"]
#eliminates the folds and responses from the data
data_test <- data_test %>% select(-cl, -folds)
#pedics the response of the test data suing k-Nearest Neighbors (k = k_nn)
predict_cv <- knn(train = data_train,
cl = cl_train,
test = data_test,
k = k_nn
)
#calculates and compunds the average cv errro
cv_err <- ((sum(ifelse(cl_test == predict_cv, 0, 1)) / length(cl_test)) +
cv_err * (i - 1)) / i
}
View(data)
#loops trough the different folds testing one against the rest
for(i in 1:k_cv){
#store training data for the iteration
data_train <- data %>% filter(folds != i)
#records the response for the training data
cl_train <- data_train["cl"]
#eliminates the folds and responses from the data
data_train <- data_train %>% select(-cl, -folds)
#store testing data for the iteration
data_test <- data %>% filter(folds == i)
#records the response for the testing data
cl_test <- data_test["cl"]
#eliminates the folds and responses from the data
data_test <- data_test %>% select(-cl, -folds)
#pedics the response of the test data suing k-Nearest Neighbors (k = k_nn)
predict_cv <- knn(train = data_train,
cl = cl_train,
test = data_test,
k = k_nn
)
#calculates and compunds the average cv errro
cv_err <- ((sum(ifelse(cl_test == predict_cv, 0, 1)) / length(cl_test)) +
cv_err * (i - 1)) / i
}
?select
libaray(dplyr)
librray(dplyr)
library(dplyr)
#My k-Nearest Neighbors Cross-Validation function
train = iris[,-5]
cl = iris[,5]
k_nn = 1
k_cv = 5
#my_knn_cv <- function(train, cl, k_nn, k_cv){
# Split data in k_cv parts, randomly
folds <- sample(rep(1:k_cv, length = nrow(train)))
# Combines input data
data <- data.frame(train, cl, folds)
#initializes cv error as 0
cv_err <- 0
#loops trough the different folds testing one against the rest
for(i in 1:k_cv){
#store training data for the iteration
data_train <- data %>% filter(folds != i)
#records the response for the training data
cl_train <- data_train["cl"]
#eliminates the folds and responses from the data
data_train <- data_train %>% select(-cl, -folds)
#store testing data for the iteration
data_test <- data %>% filter(folds == i)
#records the response for the testing data
cl_test <- data_test["cl"]
#eliminates the folds and responses from the data
data_test <- data_test %>% select(-cl, -folds)
#pedics the response of the test data suing k-Nearest Neighbors (k = k_nn)
predict_cv <- knn(train = data_train,
cl = cl_train,
test = data_test,
k = k_nn
)
#calculates and compunds the average cv errro
cv_err <- ((sum(ifelse(cl_test == predict_cv, 0, 1)) / length(cl_test)) +
cv_err * (i - 1)) / i
}
install.packages(c("broom", "cli", "covr", "crosstalk", "digest", "dplyr", "forcats", "foreign", "fs", "ggplot2", "ggrepel", "glue", "lifecycle", "modelr", "nlme", "nnet", "plyr", "rlang", "roxygen2", "shiny", "survival", "tinytex", "vctrs", "xml2"))
?my_knn
library(myfirstpackage)
?my_knn
?my_rf_cv
?my_knn_cv
my_rf_cv(3)
my_knn_cv(train = iris[,-5], cl = iris[,5], k_nn = 1, k_cv = 5)
devtools::document()
devtools::check()
my_gapminder
my_gapminder[["country"]]
my_gapminder["country"]
devtools::document()
library(magrittr)
my_knn_cv(train = iris[,-5], cl = iris[,5], k_nn = 4, k_cv = 5)
?select
detach("package:magrittr", unload = TRUE)
library(dbplyr)
my_knn_cv(train = iris[,-5], cl = iris[,5], k_nn = 4, k_cv = 5)
devtools::document()
?select
devtools::document()
library(myfirstpackage)
devtools::document()
library(myfirstpackage)
library(myfirstpackage)
?lm
my_iris
iris
devtools::document()
library(myfirstpackage)
?import
?@import
?select
library(myfirstpackage)
devtools::document()
?select
my_iris
my_iris[,-5:6]
devtools::document()
