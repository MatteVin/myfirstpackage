#eliminates the folds and responses from the data
data_test <- data_test %>% select(-cl, -folds)
#pedics the response of the test data suing k-Nearest Neighbors (k = k_nn)
predict_cv <- knn(train = data_train,
cl = cl_train,
test = data_test,
k = k_nn
)
#calculates and compunds the average cv errro
cv_err <- ((sum(ifelse(cl_test == predict_cv, 0, 1)) / length(cl_test)) +
cv_err * (i - 1)) / i
}
#My k-Nearest Neighbors Cross-Validation function
my_knn_cv <- function(train, cl, k_nn, k_cv){
# Split data in k_cv parts, randomly
folds <- sample(rep(1:k_cv, length = nrow(train)))
# Combines input data
data <- data.frame(train, cl, folds)
#initializes cv error as 0
cv_err <- 0
#loops trough the different folds testing one against the rest
for(i in 1:k_cv){
#store training data for the iteration
data_train <- data %>% filter(folds != i)
#records the response for the training data
cl_train <- data_train[["cl"]]
#eliminates the folds and responses from the data
data_train <- data_train %>% select(-cl, -folds)
#store testing data for the iteration
data_test <- data %>% filter(folds == i)
#records the response for the testing data
cl_test <- data_test["cl"]
#eliminates the folds and responses from the data
data_test <- data_test %>% select(-cl, -folds)
#pedics the response of the test data suing k-Nearest Neighbors (k = k_nn)
predict_cv <- knn(train = data_train,
cl = cl_train,
test = data_test,
k = k_nn
)
#calculates and compunds the average cv errro
cv_err <- ((sum(ifelse(cl_test == predict_cv, 0, 1)) / length(cl_test)) +
cv_err * (i - 1)) / i
}
#stores the predictions of all the data using all the data for training.
class <- knn(train = train, cl = cl, test = train, k = k_nn)
#return results
result <- list("class" = class, "cv_err" = cv_err)
return(result)
}
#run my_knn_cv with k_nn = 1
predict_knn_1 <- my_knn_cv(train = iris[,-5], cl = iris[,5], k_nn = 1, k_cv = 5)
?data.frame
#My k-Nearest Neighbors Cross-Validation function
#my_knn_cv <- function(train, cl, k_nn, k_cv){
# Split data in k_cv parts, randomly
folds <- sample(rep(1:k_cv, length = nrow(train)))
#My k-Nearest Neighbors Cross-Validation function
train = iris[,-5]
cl = iris[,5]
k_nn = 1
k_cv = 5
#my_knn_cv <- function(train, cl, k_nn, k_cv){
# Split data in k_cv parts, randomly
folds <- sample(rep(1:k_cv, length = nrow(train)))
# Combines input data
data <- data.frame(train, cl, folds)
#initializes cv error as 0
cv_err <- 0
#loops trough the different folds testing one against the rest
for(i in 1:k_cv){
#store training data for the iteration
data_train <- data %>% filter(folds != i)
#records the response for the training data
cl_train <- data_train[["cl"]]
#eliminates the folds and responses from the data
data_train <- data_train %>% select(-cl, -folds)
#store testing data for the iteration
data_test <- data %>% filter(folds == i)
#records the response for the testing data
cl_test <- data_test["cl"]
#eliminates the folds and responses from the data
data_test <- data_test %>% select(-cl, -folds)
#pedics the response of the test data suing k-Nearest Neighbors (k = k_nn)
predict_cv <- knn(train = data_train,
cl = cl_train,
test = data_test,
k = k_nn
)
#calculates and compunds the average cv errro
cv_err <- ((sum(ifelse(cl_test == predict_cv, 0, 1)) / length(cl_test)) +
cv_err * (i - 1)) / i
}
View(data)
#loops trough the different folds testing one against the rest
for(i in 1:k_cv){
#store training data for the iteration
data_train <- data %>% filter(folds != i)
#records the response for the training data
cl_train <- data_train["cl"]
#eliminates the folds and responses from the data
data_train <- data_train %>% select(-cl, -folds)
#store testing data for the iteration
data_test <- data %>% filter(folds == i)
#records the response for the testing data
cl_test <- data_test["cl"]
#eliminates the folds and responses from the data
data_test <- data_test %>% select(-cl, -folds)
#pedics the response of the test data suing k-Nearest Neighbors (k = k_nn)
predict_cv <- knn(train = data_train,
cl = cl_train,
test = data_test,
k = k_nn
)
#calculates and compunds the average cv errro
cv_err <- ((sum(ifelse(cl_test == predict_cv, 0, 1)) / length(cl_test)) +
cv_err * (i - 1)) / i
}
?select
libaray(dplyr)
librray(dplyr)
library(dplyr)
#My k-Nearest Neighbors Cross-Validation function
train = iris[,-5]
cl = iris[,5]
k_nn = 1
k_cv = 5
#my_knn_cv <- function(train, cl, k_nn, k_cv){
# Split data in k_cv parts, randomly
folds <- sample(rep(1:k_cv, length = nrow(train)))
# Combines input data
data <- data.frame(train, cl, folds)
#initializes cv error as 0
cv_err <- 0
#loops trough the different folds testing one against the rest
for(i in 1:k_cv){
#store training data for the iteration
data_train <- data %>% filter(folds != i)
#records the response for the training data
cl_train <- data_train["cl"]
#eliminates the folds and responses from the data
data_train <- data_train %>% select(-cl, -folds)
#store testing data for the iteration
data_test <- data %>% filter(folds == i)
#records the response for the testing data
cl_test <- data_test["cl"]
#eliminates the folds and responses from the data
data_test <- data_test %>% select(-cl, -folds)
#pedics the response of the test data suing k-Nearest Neighbors (k = k_nn)
predict_cv <- knn(train = data_train,
cl = cl_train,
test = data_test,
k = k_nn
)
#calculates and compunds the average cv errro
cv_err <- ((sum(ifelse(cl_test == predict_cv, 0, 1)) / length(cl_test)) +
cv_err * (i - 1)) / i
}
install.packages(c("broom", "cli", "covr", "crosstalk", "digest", "dplyr", "forcats", "foreign", "fs", "ggplot2", "ggrepel", "glue", "lifecycle", "modelr", "nlme", "nnet", "plyr", "rlang", "roxygen2", "shiny", "survival", "tinytex", "vctrs", "xml2"))
?my_knn
library(myfirstpackage)
?my_knn
?my_rf_cv
?my_knn_cv
my_rf_cv(3)
my_knn_cv(train = iris[,-5], cl = iris[,5], k_nn = 1, k_cv = 5)
devtools::document()
devtools::check()
my_gapminder
my_gapminder[["country"]]
my_gapminder["country"]
devtools::document()
library(magrittr)
my_knn_cv(train = iris[,-5], cl = iris[,5], k_nn = 4, k_cv = 5)
?select
detach("package:magrittr", unload = TRUE)
library(dbplyr)
my_knn_cv(train = iris[,-5], cl = iris[,5], k_nn = 4, k_cv = 5)
devtools::document()
?select
devtools::document()
library(myfirstpackage)
devtools::document()
library(myfirstpackage)
library(myfirstpackage)
?lm
my_iris
iris
devtools::document()
library(myfirstpackage)
?import
?@import
?select
library(myfirstpackage)
devtools::document()
?select
my_iris
my_iris[,-5:6]
devtools::document()
library(myfirstpackage)
#'
#' @param  k something something.
#' @return something must be returned.
#' @examples
#' my_rf_cv(4)
#' my_rf_cv(10)
#' @keywords shower
#' @import randomForest dplyr magrittr
#' @export
#My Random Forest Cross-Validation function
my_rf_cv <- function(k){
# Split data in k parts, randomly
folds <- sample(rep(1:k, length = nrow(my_gapminder)))
# Use data from before, leaving out species as we won't need it
data <- data.frame(my_gapminder[,6], my_gapminder[,5], folds)
#List for string cv errors on each iteration
cv_err_list <- rep(NA, k)
#loops trough the groups
for(i in 1:k) {
#set the training set
data_train <- data %>% filter(folds != i)  %>% select(-folds)
#set the testing set
data_test <- data %>% filter(folds == i)  %>% select(-folds)
#crates a random forest model on the training data
model_k_i <- randomForest(lifeExp ~ gdpPercap,
data = data_train,
ntree = 100
)
#calculates predictions on the test using the random forest model
predictions_k_i <- predict(model_k_i, data_test["lifeExp"])
#calculates the mean square error petween the predicted and true sepal.length
cv_err_list[i] <- sum((predictions_k_i - data_test["gdpPercap"])^2) /
(length(data_test[]))
}
#calculates and returns the mean cross validation MSE
cv_err <- mean(cv_err_list)
return(cv_err)
}
?my_rf_cv
my_rf_cv(1)
library(dbplyr)
library(dplyr)
detach("package:dbplyr", unload = TRUE)
my_rf_cv(1)
library(randomForest)
my_rf_cv(1)
my_rf_cv(1)
my_rf_cv(1)
my_gapminder
data.frame(my_gapminder[,6], my_gapminder[,5]
)
my_rf_cv(1)
data.frame(my_gapminder[,6], my_gapminder[,4])
my_rf_cv(1)
data.frame(my_gapminder["lifeExp"], my_gapminder["gdpPercap"], folds)
data.frame(my_gapminder["lifeExp"], my_gapminder["gdpPercap"])
#' @param  k something something.
#' @return something must be returned.
#' @examples
#' my_rf_cv(4)
#' my_rf_cv(10)
#' @keywords shower
#' @import randomForest dplyr magrittr
#'
#' @export
#My Random Forest Cross-Validation function
my_rf_cv <- function(k){
# Split data in k parts, randomly
folds <- sample(rep(1:k, length = nrow(my_gapminder)))
# Use data from before, leaving out species as we won't need it
data <- data.frame(my_gapminder["lifeExp"], my_gapminder["gdpPercap"], folds)
#List for string cv errors on each iteration
cv_err_list <- rep(NA, k)
#loops trough the groups
for(i in 1:k) {
#set the training set
data_train <- data %>% filter(folds != i)  %>% select(-folds)
#set the testing set
data_test <- data %>% filter(folds == i)  %>% select(-folds)
#crates a random forest model on the training data
model_k_i <- randomForest(lifeExp ~ gdpPercap,
data = data_train,
ntree = 100
)
#calculates predictions on the test using the random forest model
predictions_k_i <- predict(model_k_i, data_test["lifeExp"])
#calculates the mean square error petween the predicted and true sepal.length
cv_err_list[i] <- sum((predictions_k_i - data_test["gdpPercap"])^2) /
(length(data_test[]))
}
#calculates and returns the mean cross validation MSE
cv_err <- mean(cv_err_list)
return(cv_err)
}
View(my_rf_cv)
my_rf_cv(1)
?randomForest
my_rf_cv(1)
randomForest
my_rf_cv(1)
#'
#' description.
#'
#' @param  k something something.
#' @return something must be returned.
#' @keywords shower
#' @import randomForest dplyr magrittr
#'
#' @export
#My Random Forest Cross-Validation function
my_rf_cv <- function(k) {
fold <- sample(rep(1:k, length = length(my_gapminder$lifeExp)))
# data <- data.frame()
mse <- rep(NA, k)
# loop thru the folds
for (i in 1:k) {
data_train <- iris[fold != i, ] # Xi
data_test <-  iris[fold == i, ]  # Xi star
# Train our models
cl_train <- my_gapminder$lifeExp[fold != i] # Yi
cl_test <- my_gapminder$lifeExp[fold == i]  # Yi star
model <- randomForest(lifeExp ~ gdpPercap, data = data_train, ntree = 100)
predictions <- predict(model, data_test[, -1])
mse[i] <- mean((predictions - cl_test)^2)
}
output <- mean(mse)
}
my_rf_cv(4)
my_rf_cv(4)
my_rf_cv(4)
my_rf_cv(4)
library(myfirstpackage)
?my_gapminder
my_rf_cv(4)
View(my_gapminder)
my_rf_cv(4)
#'
#' description.
#'
#' @param  k something something.
#' @return something must be returned.
#' @keywords shower
#' @import randomForest dplyr magrittr
#'
#' @export
#My Random Forest Cross-Validation function
my_rf_cv <- function(k) {
fold <- sample(rep(1:k, length = length(my_gapminder[["lifeExp"]])))
# data <- data.frame()
mse <- rep(NA, k)
# loop thru the folds
for (i in 1:k) {
data_train <- iris[fold != i, ] # Xi
data_test <-  iris[fold == i, ]  # Xi star
# Train our models
cl_train <- my_gapminder$lifeExp[fold != i] # Yi
cl_test <- my_gapminder$lifeExp[fold == i]  # Yi star
model <- randomForest(lifeExp ~ gdpPercap, data = data_train, ntree = 100)
predictions <- predict(model, data_test[, -1])
mse[i] <- mean((predictions - cl_test)^2)
}
output <- mean(mse)
}
#'
#' description.
#'
#' @param  k something something.
#' @return something must be returned.
#' @keywords shower
#' @import randomForest dplyr magrittr
#'
#' @export
#My Random Forest Cross-Validation function
my_rf_cv <- function(k) {
fold <- sample(rep(1:k, length = length(my_gapminder[["lifeExp"]])))
# data <- data.frame()
mse <- rep(NA, k)
# loop thru the folds
for (i in 1:k) {
data_train <- iris[fold != i, ] # Xi
data_test <-  iris[fold == i, ]  # Xi star
# Train our models
cl_train <- my_gapminder$lifeExp[fold != i] # Yi
cl_test <- my_gapminder$lifeExp[fold == i]  # Yi star
model <- randomForest(lifeExp ~ gdpPercap, data = data_train, ntree = 100)
predictions <- predict(model, data_test[, -1])
mse[i] <- mean((predictions - cl_test)^2)
}
output <- mean(mse)
}
my_rf_cv(4)
my_rf_cv(4)
force(my_pow)
force(my_lm)
force(my_knn_cv)
force(my_iris)
force(my_t_test)
force(f_to_c)
my_rf_cv(4)
my_rf_cv(4)
devtools::document()
devtools::document()
library(myfirstpackage)
my_rf_cv(2)
dplyr
my_rf_cv(2)
force(my_t_test)
my_rf_cv(2)
#' Random Forest Cross-Validation
#'
#' @import class magrittr randomForest dplyr
#' @importFrom magrittr %>%
#' @export
#My Random Forest Cross-Validation function
my_rf_cv <- function(k){
# Split data in k parts, randomly
folds <- sample(rep(1:k, length = nrow(my_iris)))
# Use data from before, leaving out species as we won't need it
data <- data.frame(my_iris[,-5], folds)
#List for string cv errors on each iteration
cv_err_list <- rep(NA, k)
#loops trough the groups
for(i in 1:k) {
#set the training set
data_train <- data %>% filter(folds != i)  %>% select(-folds)
#set the testing set
data_test <- data %>% filter(folds == i)  %>% select(-folds)
#crates a random forest model on the training data
model_k_i <-
randomForest(Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width,
data = data_train,
ntree = 100
)
#calculates predictions on the test using the random forest model
predictions_k_i <- predict(model_k_i, data_test[, -1])
#calculates the mean square error petween the predicted and true sepal.length
cv_err_list[i] <- sum((predictions_k_i - data_test[, 1])^2) /
(length(data_test[, 1]))
}
#calculates and returns the mean cross validation MSE
cv_err <- mean(cv_err_list)
return(cv_err)
}
my_rf_cv(2)
my_rf_cv(2)
dplyr::
dplyr::
my_rf_cv(2)
my_rf_cv(2)
my_rf_cv(2)
devtools::document()
my_rf_cv(2)
my_iris[,-5]
data <- data.frame(my_iris[,-5], folds)
folds <- sample(rep(1:k, length = nrow(my_iris)))
folds <- sample(rep(1:5, length = nrow(my_iris)))
data <- data.frame(my_iris[,-5], folds)
data_train <- data %>% filter(folds != 1)  %>% select(-folds)
data
data %>% select(-folds)
library(myfirstpackage)
library(myfirstpackage)
?my_lm
?my_rf_cv
my_rf_cv(2)
library(magrittr)
The following object is masked _by_ ‘.GlobalEnv’:
my_rf_cv(2)
library(dplyr)
my_rf_cv(2)
library(randomForest)
my_rf_cv(2)
force(`n'est pas`)
force(f_to_c)
?force
View(t.test)
View(t.test)
View(runif)
View(rstandard)
View(add1)
View(aggregate)
View(anova)
View(anova)
force(approx)
usethis::use_testthat()
use_test()
library(testthat)
library(myfirstpackage)
test_check("myfirstpackage")
test_check("myfirstpackage")
test_dir()
test_that()
library(myfirstpackage)
devtools::document()
devtools::document()
library(myfirstpackage)
library(myfirstpackage)
my_lm(formula = lifeExp ~ gdpPercap + continent,
data = my_gapminder), "data.frame")
my_lm(formula = lifeExp ~ gdpPercap + continent,
data = my_gapminder), "data.frame")
my_lm(formula = lifeExp ~ gdpPercap + continent,
data = my_gapminder)
?solve
?model.response
library(myfirstpackage)
data("mtcars")
my_result <- my_lm(mpg ~ hp + wt, mtcars)
my_result
my_lm(formula = lifeExp ~ gdpPercap + continent,
data = my_gapminder
)
